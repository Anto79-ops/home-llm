{
  "domain": "llama_conversation",
  "name": "LLaMA Conversation",
  "codeowners": ["@acon96"],
  "config_flow": true,
  "dependencies": ["conversation"],
  "documentation": "https://www.home-assistant.io/integrations/llama_conversation",
  "integration_type": "service",
  "iot_class": "local_polling",
  "requirements": [
    "transformers==4.34.1",
    "torch==2.1.0",
    "einops==0.7.0"
  ]
}
